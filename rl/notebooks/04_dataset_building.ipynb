{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Building\n",
    "\n",
    "Build training dataset from generated rules and preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "sys.path.append(str(Path('../core').resolve()))\n",
    "sys.path.append(str(Path('../evaluation').resolve()))\n",
    "\n",
    "from synthetic_preference_generator import (\n",
    "    SyntheticPreferenceGenerator,\n",
    "    IntentRule,\n",
    "    load_rules_from_generated_file\n",
    ")\n",
    "from quality_metrics import QualityMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test: 0.8/0.1/0.1\n"
     ]
    }
   ],
   "source": [
    "RULES_PATH = Path('../data/generated_rules/rules.jsonl')\n",
    "DATASET_PATH = Path('../data/training_dataset')\n",
    "OUTPUT_FILE = DATASET_PATH / 'synthetic_preferences.jsonl'\n",
    "DATASET_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "config_path = Path('../config/training_config.json')\n",
    "with open(config_path, 'r') as f:\n",
    "    training_config = json.load(f)\n",
    "\n",
    "print(f\"Train/Val/Test: {training_config['data_config']['train_split']}/{training_config['data_config']['val_split']}/{training_config['data_config']['test_split']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Generated Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No rules file at ../data/generated_rules/rules.jsonl\n",
      "Run 03_rule_generation.ipynb first\n"
     ]
    }
   ],
   "source": [
    "if RULES_PATH.exists():\n",
    "    trace_rules = load_rules_from_generated_file(str(RULES_PATH))\n",
    "    total_rules = sum(len(rules) for rules in trace_rules.values())\n",
    "    print(f\"Loaded {total_rules} rules from {len(trace_rules)} traces\")\n",
    "else:\n",
    "    print(f\"No rules file at {RULES_PATH}\")\n",
    "    print(\"Run 03_rule_generation.ipynb first\")\n",
    "    trace_rules = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator initialized\n"
     ]
    }
   ],
   "source": [
    "generator = SyntheticPreferenceGenerator(\n",
    "    confidence_threshold_high=0.7,\n",
    "    confidence_threshold_low=0.4,\n",
    "    min_novelty_score=0.3,\n",
    "    require_platform_context=True,\n",
    "    synthetic_weight=0.3,\n",
    "    group_by_dimension=True,\n",
    "    group_by_platform=True\n",
    ")\n",
    "print(f\"Generator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trace_rules:\n",
    "    all_pairs = generator.generate_from_trace_batch(\n",
    "        trace_rules,\n",
    "        strategies=['confidence', 'quality', 'completeness', 'novelty', 'frequency', 'constitutional']\n",
    "    )\n",
    "    print(f\"Generated {len(all_pairs)} preference pairs\")\n",
    "    \n",
    "    source_counts = Counter(p.source for p in all_pairs)\n",
    "    print(\"\\nBy strategy:\")\n",
    "    for source, count in sorted(source_counts.items(), key=lambda x: -x[1]):\n",
    "        print(f\"  {source}: {count}\")\n",
    "else:\n",
    "    all_pairs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format for DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No preference pairs generated\n"
     ]
    }
   ],
   "source": [
    "if all_pairs:\n",
    "    dpo_examples = generator.format_for_dpo(all_pairs, include_weights=True, include_grouping=True)\n",
    "    print(f\"Formatted {len(dpo_examples)} DPO examples\")\n",
    "    print(\"\\nSample:\")\n",
    "    print(json.dumps(dpo_examples[0], indent=2)[:500] + \"...\")\n",
    "else:\n",
    "    dpo_examples = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No examples to save\n"
     ]
    }
   ],
   "source": [
    "if dpo_examples:\n",
    "    with open(OUTPUT_FILE, 'w') as f:\n",
    "        for ex in dpo_examples:\n",
    "            f.write(json.dumps(ex) + '\\n')\n",
    "    print(f\"Saved {len(dpo_examples)} examples to {OUTPUT_FILE}\")\n",
    "    \n",
    "    metadata = {\n",
    "        'created_at': datetime.now().isoformat(),\n",
    "        'total_examples': len(dpo_examples),\n",
    "        'source_distribution': dict(source_counts),\n",
    "        'strategies_used': ['confidence', 'quality', 'completeness', 'novelty', 'frequency', 'constitutional']\n",
    "    }\n",
    "    with open(DATASET_PATH / 'metadata.json', 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    print(f\"Saved metadata\")\n",
    "else:\n",
    "    print(\"No examples to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- 05_dataset_analysis.ipynb: Analyze distribution\n",
    "- 06_pre_training_validation.ipynb: Validate before training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
